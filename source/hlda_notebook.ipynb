{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hlda.sampler import HierarchicalLDA\n",
    "from util.file_loader import FileLoader\n",
    "from pandas import DataFrame\n",
    "import os\n",
    "import numpy as np\n",
    "from ipywidgets import widgets\n",
    "from IPython.core.display import HTML, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl = FileLoader()\n",
    "dir = \"cpp_examples/assembly/\"\n",
    "files = os.listdir(dir)\n",
    "asm_files = []\n",
    "for f in files:\n",
    "    if f[-8:] == \"only.txt\":\n",
    "        fl.addFilename(dir + f)\n",
    "\n",
    "data_files = fl.getData(type=np.dtype('unicode_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_corpus(d):\n",
    "    uni = set()\n",
    "    docs = []\n",
    "    for data in d:\n",
    "        uni.update(data[1])\n",
    "        docs.append(data[1])\n",
    "    vocab = sorted(list(uni))\n",
    "    word_to_id = dict((w, id) for id, w in enumerate(vocab))\n",
    "    corpus = [[0 for word in doc] for doc in docs]\n",
    "    for r in range(len(corpus)):\n",
    "        doc = docs[r]\n",
    "        for c in range(len(corpus[r])):\n",
    "            word = doc[c]\n",
    "            corpus[r][c] = word_to_id[word]\n",
    "\n",
    "    return corpus, vocab, word_to_id, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, vocab, word_id, docs = construct_corpus(data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 500       # no of iterations for the sampler\n",
    "alpha = .1           # smoothing over level distributions/\n",
    "gamma = 1.0           # CRP smoothing parameter; number of imaginary customers at next, as yet unused table\n",
    "eta = 0.1             # smoothing over topic-word distributions\n",
    "num_levels = 2        # the number of levels in the tree\n",
    "display_topics = 50   # the number of iterations between printing a brief summary of the topics so far\n",
    "n_words = 5           # the number of most probable words to print for each topic after model estimation\n",
    "with_weights = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HierarchicalLDA sampling\n",
      ".................................................. 50\n",
      "topic 0 (level=0, total_words=2663, documents=16): mov (418), lea (312), push (243), callq (236), pop (215), \n",
      "    topic 1 (level=1, total_words=1284, documents=14): mov (749), add (133), cltq (61), sar (46), lea (26), \n",
      "    topic 4 (level=1, total_words=452, documents=2): mov (257), add (42), sub (23), addl (20), cltq (18), \n",
      ".................................................. 100\n",
      "topic 0 (level=0, total_words=2929, documents=16): mov (609), lea (354), push (249), callq (236), pop (235), \n",
      "    topic 1 (level=1, total_words=1064, documents=14): mov (596), add (132), sub (72), cltq (55), cmp (37), \n",
      "    topic 4 (level=1, total_words=406, documents=2): mov (219), add (42), sub (28), addl (20), cmp (19), \n",
      ".................................................. 150\n",
      "topic 0 (level=0, total_words=3303, documents=16): mov (744), lea (321), push (269), callq (236), pop (220), \n",
      "    topic 1 (level=1, total_words=550, documents=10): mov (378), cmp (31), jge (18), xor (15), shr (14), \n",
      "    topic 4 (level=1, total_words=546, documents=6): mov (302), addl (27), jge (26), sub (25), add (24), \n",
      ".................................................. 200\n",
      "topic 0 (level=0, total_words=4075, documents=16): mov (1283), lea (326), push (267), pop (235), callq (234), \n",
      "    topic 1 (level=1, total_words=41, documents=8): mov (16), cvtsi2sd (4), test (4), cvttsd2si (3), cvtsi2sdl (2), \n",
      "    topic 4 (level=1, total_words=283, documents=8): mov (125), lea (28), addl (20), movslq (18), add (18), \n",
      ".................................................. 250\n",
      "topic 0 (level=0, total_words=4183, documents=16): mov (1337), lea (354), push (266), callq (236), pop (235), \n",
      "    topic 1 (level=1, total_words=35, documents=8): movl (6), cvtsi2sd (4), jmpq (3), cvttsd2si (3), nopl (3), \n",
      "    topic 4 (level=1, total_words=181, documents=8): mov (87), addl (19), movslq (18), sub (11), jge (11), \n",
      ".................................................. 300\n",
      "topic 0 (level=0, total_words=4061, documents=16): mov (1267), lea (337), push (269), pop (235), callq (231), \n",
      "    topic 1 (level=1, total_words=42, documents=7): movl (18), nopl (5), cvtsi2sd (4), movapd (2), addsd (2), \n",
      "    topic 4 (level=1, total_words=296, documents=9): mov (157), add (25), lea (17), addl (16), movslq (16), \n",
      ".................................................. 350\n",
      "topic 0 (level=0, total_words=4145, documents=16): mov (1289), lea (354), push (269), callq (236), pop (235), \n",
      "    topic 1 (level=1, total_words=45, documents=9): movl (23), cvtsi2sd (4), cvttsd2si (3), movapd (2), cvtsi2sdl (2), \n",
      "    topic 4 (level=1, total_words=209, documents=7): mov (135), addl (19), movslq (18), shl (9), jge (8), \n",
      ".................................................. 400\n",
      "topic 0 (level=0, total_words=4096, documents=16): mov (1291), lea (352), push (269), callq (231), pop (230), \n",
      "    topic 1 (level=1, total_words=57, documents=7): movl (27), cvtsi2sd (4), nopw (3), jmp (3), cvttsd2si (3), \n",
      "    topic 4 (level=1, total_words=246, documents=9): mov (133), add (29), movslq (18), addl (11), jge (11), \n",
      ".................................................. 450\n",
      "topic 0 (level=0, total_words=4191, documents=16): mov (1321), lea (354), push (267), callq (236), pop (235), \n",
      "    topic 1 (level=1, total_words=30, documents=8): movl (7), cvtsi2sd (4), cvttsd2si (3), cvtsi2sdl (2), movapd (2), \n",
      "    topic 4 (level=1, total_words=178, documents=8): mov (103), movslq (16), addl (11), cmp (10), jge (9), \n",
      ".................................................. 500\n",
      "topic 0 (level=0, total_words=4132, documents=16): mov (1319), lea (340), push (269), callq (236), pop (235), \n",
      "    topic 1 (level=1, total_words=56, documents=8): movl (26), jmpq (5), cvtsi2sd (4), cvttsd2si (3), cvtsi2sdl (2), \n",
      "    topic 4 (level=1, total_words=211, documents=8): mov (104), add (17), movslq (17), addl (16), lea (14), \n"
     ]
    }
   ],
   "source": [
    "hlda = HierarchicalLDA(X, vocab, alpha=alpha, gamma=gamma, eta=eta, num_levels=num_levels)\n",
    "hlda.estimate(n_samples, display_topics=display_topics, n_words=n_words, with_weights=with_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "colour_map = {\n",
    "    0: 'blue',\n",
    "    1: 'black',\n",
    "    2: 'green'\n",
    "}\n",
    "\n",
    "def show_doc(d=0):\n",
    "    \n",
    "    node = hlda.document_leaves[d]\n",
    "    path = []\n",
    "    while node is not None:\n",
    "        path.append(node)\n",
    "        node = node.parent\n",
    "    path.reverse()   \n",
    "    \n",
    "    n_words = 10\n",
    "    with_weights = False    \n",
    "    for n in range(len(path)):\n",
    "        node = path[n]\n",
    "        colour = colour_map[n] \n",
    "        msg = 'Level %d Topic %d: ' % (node.level, node.node_id)\n",
    "        msg += node.get_top_words(n_words, with_weights)\n",
    "        output = '<h%d><span style=\"color:%s\">%s</span></h3>' % (n+1, colour, msg)\n",
    "        display(HTML(output))\n",
    "        \n",
    "    display(HTML('<hr/><h5>Processed Document: ' + data_files[d][0].getFullName() +'</h5>'))\n",
    "\n",
    "    doc = docs[d]\n",
    "    output = ''\n",
    "    for n in range(len(doc)):\n",
    "        w = doc[n]\n",
    "        l = hlda.levels[d][n]\n",
    "        colour = colour_map[l]\n",
    "        output += '<span style=\"color:%s\">%s</span> ' % (colour, w)\n",
    "    display(HTML(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24e3fbf5c72d4e479524c114d0e892ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='d', max=15), Output()), _dom_classes=('widget-interact',â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.show_doc(d=0)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "widgets.interact(show_doc, d=(0, len(docs)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hlda.sampler import HierarchicalLDA\n",
    "from util.file_loader import FileLoader\n",
    "from pandas import DataFrame\n",
    "import os\n",
    "import numpy as np\n",
    "from ipywidgets import widgets\n",
    "from IPython.core.display import HTML, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl = FileLoader()\n",
    "dir = \"cpp_examples/assembly/\"\n",
    "files = os.listdir(dir)\n",
    "asm_files = []\n",
    "for f in files:\n",
    "    if f[-8:] == \"only.txt\":\n",
    "        fl.addFilename(dir + f)\n",
    "\n",
    "data_files = fl.getData(type=np.dtype('unicode_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_corpus(d):\n",
    "    uni = set()\n",
    "    docs = []\n",
    "    for data in d:\n",
    "        uni.update(data[1])\n",
    "        docs.append(data[1])\n",
    "    vocab = sorted(list(uni))\n",
    "    word_to_id = dict((w, id) for id, w in enumerate(vocab))\n",
    "    corpus = [[0 for word in doc] for doc in docs]\n",
    "    for r in range(len(corpus)):\n",
    "        doc = docs[r]\n",
    "        for c in range(len(corpus[r])):\n",
    "            word = doc[c]\n",
    "            corpus[r][c] = word_to_id[word]\n",
    "\n",
    "    return corpus, vocab, word_to_id, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, vocab, word_id, docs = construct_corpus(data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 500       # no of iterations for the sampler\n",
    "alpha = .1           # smoothing over level distributions/\n",
    "gamma = 1.0           # CRP smoothing parameter; number of imaginary customers at next, as yet unused table\n",
    "eta = 0.1             # smoothing over topic-word distributions\n",
    "num_levels = 2        # the number of levels in the tree\n",
    "display_topics = 50   # the number of iterations between printing a brief summary of the topics so far\n",
    "n_words = 5           # the number of most probable words to print for each topic after model estimation\n",
    "with_weights = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HierarchicalLDA sampling\n",
      ".................................................. 50\n",
      "topic 0 (level=0, total_words=3981, documents=16): mov (1285), lea (322), push (255), pop (219), callq (179), \n",
      "    topic 1 (level=1, total_words=372, documents=12): mov (139), callq (57), lea (32), pop (16), nopl (16), \n",
      "    topic 3 (level=1, total_words=46, documents=4): movl (16), retq (5), cvtsi2sd (4), cvttsd2si (3), hlt (3), \n",
      ".................................................. 100\n",
      "topic 0 (level=0, total_words=4072, documents=16): mov (1274), lea (352), push (269), callq (236), pop (235), \n",
      "    topic 1 (level=1, total_words=286, documents=10): mov (150), sub (22), movslq (18), addl (17), add (14), \n",
      "    topic 3 (level=1, total_words=41, documents=6): movl (16), cvtsi2sd (4), cvttsd2si (3), sub (2), cmpq (2), \n",
      ".................................................. 150\n",
      "topic 0 (level=0, total_words=4133, documents=16): mov (1307), lea (352), push (269), callq (236), pop (235), \n",
      "    topic 1 (level=1, total_words=229, documents=11): mov (117), add (19), addl (19), movslq (18), jge (14), \n",
      "    topic 3 (level=1, total_words=37, documents=5): movl (8), cvtsi2sd (4), cvttsd2si (3), lea (2), addsd (2), \n",
      ".................................................. 200\n",
      "topic 0 (level=0, total_words=4196, documents=16): mov (1364), lea (353), push (266), callq (235), pop (235), \n",
      "    topic 1 (level=1, total_words=150, documents=9): mov (60), addl (18), movslq (17), add (11), jge (11), \n",
      "    topic 3 (level=1, total_words=53, documents=7): movl (25), test (4), cvtsi2sd (4), cvttsd2si (3), cvtsi2sdl (2), \n",
      ".................................................. 250\n",
      "topic 0 (level=0, total_words=4174, documents=16): mov (1336), lea (341), push (269), pop (235), callq (231), \n",
      "    topic 1 (level=1, total_words=187, documents=11): mov (88), add (23), movslq (16), lea (13), addl (12), \n",
      "    topic 3 (level=1, total_words=38, documents=5): movl (12), cvtsi2sd (4), cvttsd2si (3), cvtsi2sdl (2), cmpb (2), \n",
      ".................................................. 300\n",
      "topic 0 (level=0, total_words=4174, documents=16): mov (1333), lea (354), push (269), callq (236), pop (235), \n",
      "    topic 1 (level=1, total_words=189, documents=9): mov (91), add (21), movslq (18), addl (16), shl (9), \n",
      "    topic 3 (level=1, total_words=36, documents=7): movl (10), sar (4), cvtsi2sd (4), cvttsd2si (3), movapd (2), \n",
      ".................................................. 350\n",
      "topic 0 (level=0, total_words=4235, documents=16): mov (1364), lea (354), push (269), callq (236), pop (235), \n",
      "    topic 1 (level=1, total_words=133, documents=11): mov (60), movslq (18), addl (15), cltq (9), shl (9), \n",
      "    topic 3 (level=1, total_words=31, documents=5): movl (5), cvtsi2sd (4), cvttsd2si (3), cvtsi2sdl (2), jg (2), \n",
      ".................................................. 400\n",
      "topic 0 (level=0, total_words=4132, documents=16): mov (1314), lea (354), push (266), callq (236), pop (233), \n",
      "    topic 1 (level=1, total_words=224, documents=12): mov (110), add (18), movslq (18), jge (15), addl (13), \n",
      "    topic 3 (level=1, total_words=43, documents=4): movl (11), cmp (6), cvtsi2sd (4), push (3), cvtsi2sdl (2), \n",
      ".................................................. 450\n",
      "topic 0 (level=0, total_words=4145, documents=16): mov (1326), lea (354), push (264), callq (236), pop (232), \n",
      "    topic 1 (level=1, total_words=205, documents=10): mov (98), add (18), movslq (18), sub (18), addl (15), \n",
      "    topic 3 (level=1, total_words=49, documents=6): movl (14), push (5), cvtsi2sd (4), cvttsd2si (3), pop (3), \n",
      ".................................................. 500\n",
      "topic 0 (level=0, total_words=4175, documents=16): mov (1310), lea (351), push (268), callq (236), pop (235), \n",
      "    topic 1 (level=1, total_words=169, documents=10): mov (114), movslq (18), addl (17), shl (9), div (4), \n",
      "    topic 3 (level=1, total_words=55, documents=6): movl (19), cvtsi2sd (4), lea (3), cvttsd2si (3), jle (2), \n"
     ]
    }
   ],
   "source": [
    "hlda = HierarchicalLDA(X, vocab, alpha=alpha, gamma=gamma, eta=eta, num_levels=num_levels)\n",
    "hlda.estimate(n_samples, display_topics=display_topics, n_words=n_words, with_weights=with_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "colour_map = {\n",
    "    0: 'blue',\n",
    "    1: 'black',\n",
    "    2: 'green'\n",
    "}\n",
    "\n",
    "def show_doc(d=0):\n",
    "    \n",
    "    node = hlda.document_leaves[d]\n",
    "    path = []\n",
    "    while node is not None:\n",
    "        path.append(node)\n",
    "        node = node.parent\n",
    "    path.reverse()   \n",
    "    \n",
    "    n_words = 10\n",
    "    with_weights = False    \n",
    "    for n in range(len(path)):\n",
    "        node = path[n]\n",
    "        colour = colour_map[n] \n",
    "        msg = 'Level %d Topic %d: ' % (node.level, node.node_id)\n",
    "        msg += node.get_top_words(n_words, with_weights)\n",
    "        output = '<h%d><span style=\"color:%s\">%s</span></h3>' % (n+1, colour, msg)\n",
    "        display(HTML(output))\n",
    "        \n",
    "    display(HTML('<hr/><h5>Processed Document: ' + data_files[d][0].getFullName() +'</h5>'))\n",
    "\n",
    "    doc = docs[d]\n",
    "    output = ''\n",
    "    for n in range(len(doc)):\n",
    "        w = doc[n]\n",
    "        l = hlda.levels[d][n]\n",
    "        colour = colour_map[l]\n",
    "        output += '<span style=\"color:%s\">%s</span> ' % (colour, w)\n",
    "    display(HTML(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6adbca81b1f4326aeffc5d36fd1198b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='d', max=15), Output()), _dom_classes=('widget-interact',â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.show_doc(d=0)>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "widgets.interact(show_doc, d=(0, len(docs)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
